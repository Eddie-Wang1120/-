# 1. 模型剪枝基础
## 1.1. 什么是模型剪枝
深度学习网络模型从卷积层到全连接层存在着大量冗余的参数，大量神经元激活值趋近于0，将这些神经元去除后可以表现出同样的模型表达能力，这种情况被称为过参数化，而对应的技术则被称为模型剪枝。
神经元剪枝 -->  
- Dropout  
随机神经元输出置零
- DropConnect  
随机神经元之间连接置零  
![](https://pic1.zhimg.com/80/v2-6e8c9ebee7895c2aeb36ffb05fa3e05c_720w.webp)
- 细粒度剪枝(fine-grained)：即对连接或者神经元进行剪枝，它是粒度最小的剪枝。
- 向量剪枝(vector-level)：它相对于细粒度剪枝粒度更大，属于对卷积核内部(intra-kernel)的剪枝。
- 核剪枝(kernel-level)：即去除某个卷积核，它将丢弃对输入通道中对应计算通道的响应。
- 滤波器剪枝(Filter-level)：对整个卷积核组进行剪枝，会造成推理过程中输出特征通道数的改变。  
细粒度剪枝(fine-grained)，向量剪枝(vector-level)，核剪枝(kernel-level)方法被称之为非结构化剪枝  
滤波器剪枝(Filter-level)被称为结构化剪枝，对整个网络层的剪枝也被称为结构化剪枝

## 1.2. 模型剪枝必要性
稀疏大模型和稠密小模型的性能对比，在图像和语音任务上表明稀疏大模型普遍有更好的性能。  
![](https://pic1.zhimg.com/80/v2-91ef38dfe21f70f702627ea4240f3690_720w.webp)  
## 2. 模型剪枝核心算法
### 2.1. 细粒度剪枝核心技术
对权重连接和神经元进行剪枝  
![](https://pic4.zhimg.com/80/v2-3bd002b2b523d64215d2b06e860871ff_720w.webp)  
重点：  
- 如何评估连接重要性
1. 基于权重幅度  
第一步：训练一个基准模型。  

第二步：对权重值的幅度进行排序，去掉低于一个预设阈值的连接，得到剪枝后的网络。  

第三步：对剪枝后网络进行微调以恢复损失的性能，然后继续进行第二步，依次交替，直到满足终止条件，比如精度下降在一定范围内。  

虽然简单但事实上未必权重大就重要性高  
2. 基于优化目标  
![](https://pic3.zhimg.com/80/v2-69554cb10f95edc695a262f6f1c4f016_720w.webp)  

- 粗粒度剪枝核心技术（通道剪枝）
更加有用 --> 得到不需要专门算法支持的精简小模型  
1. 基于重要性因子  
Network Trimming通过激活的稀疏性来判断一个通道的重要性，认为拥有更高稀疏性的通道更应该被去除。主观性太强
2. 利用重建误差指导剪枝  
根据输入特征图的各个通道对输出特征图的贡献大小来完成剪枝过程，可以直接反映剪枝前后特征的损失情况。  
![](https://pic2.zhimg.com/80/v2-2bda30032809231bde55e6274c9a069d_720w.webp)  
3. 基于优化目标衡量通道敏感性