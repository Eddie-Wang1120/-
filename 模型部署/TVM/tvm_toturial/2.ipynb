{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tvm\n",
    "import tvm.testing\n",
    "from tvm import te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tvm.te.tensor.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "tgt = \"cuda\"\n",
    "\n",
    "tag_host = \"llvm\"\n",
    "\n",
    "n = te.var(\"n\")\n",
    "A = te.placeholder((n,), name=\"A\")\n",
    "B = te.placeholder((n,), name=\"B\")\n",
    "C = te.compute(A.shape, lambda i:A[i]+B[i], name=\"C\")\n",
    "print(type(C))\n",
    "\n",
    "#TVM 自定义Tensor Expression\n",
    "#符号变量n 表示形状\n",
    "#占位符张量A,B,C\n",
    "#静态计算图 只声明过程 不进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = te.create_schedule(C.op)\n",
    "bx, tx = s[C].split(C.op.axis[0], factor=64)\n",
    "#以64为一组计算\n",
    "# for (int bx = 0; bx < ceil(n / 64); ++bx) {\n",
    "#   for (int tx = 0; tx < 64; ++tx) {\n",
    "#     int i = bx * 64 + tx;\n",
    "#     if (i < n) {\n",
    "#       C[i] = A[i] + B[i];\n",
    "#     }\n",
    "#   }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tgt == \"cuda\" or tgt == \"rocm\" or tgt.startswith(\"opencl\"):\n",
    "    s[C].bind(bx, te.thread_axis(\"blockIdx.x\"))\n",
    "    s[C].bind(tx, te.thread_axis(\"threadIdx.x\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wjh/disk/apache-tvm-src-v0.9.0/python/tvm/driver/build_module.py:268: UserWarning: target_host parameter is going to be deprecated. Please pass in tvm.target.Target(target, host=target_host) instead.\n",
      "  \"target_host parameter is going to be deprecated. \"\n"
     ]
    }
   ],
   "source": [
    "fadd = tvm.build(s, [A, B, C], tgt, target_host=tag_host, name=\"myadd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = tvm.device(tgt, 0)\n",
    "\n",
    "n = 1024\n",
    "a = tvm.nd.array(np.random.uniform(size=n).astype(A.dtype), dev)\n",
    "b = tvm.nd.array(np.random.uniform(size=n).astype(B.dtype), dev)\n",
    "c = tvm.nd.array(np.random.uniform(size=n).astype(C.dtype), dev)\n",
    "fadd(a, b, c)\n",
    "tvm.testing.assert_allclose(c.asnumpy(), a.asnumpy() + b.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----GPU code-----\n",
      "\n",
      "#ifdef _WIN32\n",
      "  using uint = unsigned int;\n",
      "  using uchar = unsigned char;\n",
      "  using ushort = unsigned short;\n",
      "  using int64_t = long long;\n",
      "  using uint64_t = unsigned long long;\n",
      "#else\n",
      "  #define uint unsigned int\n",
      "  #define uchar unsigned char\n",
      "  #define ushort unsigned short\n",
      "  #define int64_t long long\n",
      "  #define uint64_t unsigned long long\n",
      "#endif\n",
      "extern \"C\" __global__ void __launch_bounds__(64) myadd_kernel0(float* __restrict__ C, float* __restrict__ A, float* __restrict__ B, int n, int stride, int stride1, int stride2) {\n",
      "  if (((int)blockIdx.x) < (n >> 6)) {\n",
      "    C[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) * stride)] = (A[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) * stride1)] + B[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) * stride2)]);\n",
      "  } else {\n",
      "    if (((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) < n) {\n",
      "      C[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) * stride)] = (A[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) * stride1)] + B[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) * stride2)]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if tgt == \"cuda\" or tgt == \"rocm\" or tgt.startswith(\"opencl\"):\n",
    "    dev_module = fadd.imported_modules[0]\n",
    "    print(\"-----GPU code-----\")\n",
    "    print(dev_module.get_source())\n",
    "else:\n",
    "    print(fadd.get_source())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When and where should be the value at each coordinate in each function be computed?\n",
    "# Where should they be stored?\n",
    "# How long are values cached and communicated across multiple consumers, and when are they independently recomputed by each?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@main = primfn(A_1: handle, B_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [1024], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [1], [])}\n",
      "  buffer_map = {A_1: A, B_1: B}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [1024], []), B_1: B_3: Buffer(B_2, float32, [1], [])} {\n",
      "  B[0] = 0f32\n",
      "  for (k: int32, 0, 1024) {\n",
      "    B[0] = (B[0] + A[k])\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "---------cutting line---------\n",
      "@main = primfn(A_1: handle, B_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [1024], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [1], [])}\n",
      "  buffer_map = {A_1: A, B_1: B}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [1024], []), B_1: B_3: Buffer(B_2, float32, [1], [])} {\n",
      "  B[0] = 0f32\n",
      "  for (k.inner: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[k.inner])\n",
      "  }\n",
      "  for (k.inner_1: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_1 + 32)])\n",
      "  }\n",
      "  for (k.inner_2: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_2 + 64)])\n",
      "  }\n",
      "  for (k.inner_3: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_3 + 96)])\n",
      "  }\n",
      "  for (k.inner_4: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_4 + 128)])\n",
      "  }\n",
      "  for (k.inner_5: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_5 + 160)])\n",
      "  }\n",
      "  for (k.inner_6: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_6 + 192)])\n",
      "  }\n",
      "  for (k.inner_7: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_7 + 224)])\n",
      "  }\n",
      "  for (k.inner_8: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_8 + 256)])\n",
      "  }\n",
      "  for (k.inner_9: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_9 + 288)])\n",
      "  }\n",
      "  for (k.inner_10: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_10 + 320)])\n",
      "  }\n",
      "  for (k.inner_11: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_11 + 352)])\n",
      "  }\n",
      "  for (k.inner_12: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_12 + 384)])\n",
      "  }\n",
      "  for (k.inner_13: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_13 + 416)])\n",
      "  }\n",
      "  for (k.inner_14: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_14 + 448)])\n",
      "  }\n",
      "  for (k.inner_15: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_15 + 480)])\n",
      "  }\n",
      "  for (k.inner_16: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_16 + 512)])\n",
      "  }\n",
      "  for (k.inner_17: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_17 + 544)])\n",
      "  }\n",
      "  for (k.inner_18: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_18 + 576)])\n",
      "  }\n",
      "  for (k.inner_19: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_19 + 608)])\n",
      "  }\n",
      "  for (k.inner_20: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_20 + 640)])\n",
      "  }\n",
      "  for (k.inner_21: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_21 + 672)])\n",
      "  }\n",
      "  for (k.inner_22: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_22 + 704)])\n",
      "  }\n",
      "  for (k.inner_23: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_23 + 736)])\n",
      "  }\n",
      "  for (k.inner_24: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_24 + 768)])\n",
      "  }\n",
      "  for (k.inner_25: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_25 + 800)])\n",
      "  }\n",
      "  for (k.inner_26: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_26 + 832)])\n",
      "  }\n",
      "  for (k.inner_27: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_27 + 864)])\n",
      "  }\n",
      "  for (k.inner_28: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_28 + 896)])\n",
      "  }\n",
      "  for (k.inner_29: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_29 + 928)])\n",
      "  }\n",
      "  for (k.inner_30: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_30 + 960)])\n",
      "  }\n",
      "  for (k.inner_31: int32, 0, 32) {\n",
      "    B[0] = (B[0] + A[(k.inner_31 + 992)])\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 1024\n",
    "A = te.placeholder((n,), name='A')\n",
    "k = te.reduce_axis((0, n), name='k')\n",
    "\n",
    "B = te.compute((1,), lambda i:te.sum(A[k], axis=k), name='B')\n",
    "\n",
    "s = te.create_schedule(B.op)\n",
    "\n",
    "print(tvm.lower(s, [A, B], simple_mode=True))\n",
    "print(\"---------cutting line---------\")\n",
    "\n",
    "ko, ki = s[B].split(B.op.reduce_axis[0], factor=32)\n",
    "# s[B].unroll(ki)\n",
    "s[B].unroll(ko)\n",
    "\n",
    "print(tvm.lower(s, [A, B], simple_mode=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@main = primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [1048576], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [1048576], []),\n",
      "             C: Buffer(C_2: Pointer(float32), float32, [1048576], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, C_1: C}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [1024, 1024], []), B_1: B_3: Buffer(B_2, float32, [1024, 1024], []), C_1: C_3: Buffer(C_2, float32, [1024, 1024], [])} {\n",
      "  for (i.outer: int32, 0, 32) {\n",
      "    for (i.inner: int32, 0, 32) {\n",
      "      for (j.outer: int32, 0, 32) {\n",
      "        for (j.inner: int32, 0, 32) {\n",
      "          let cse_var_1: int32 = ((((i.outer*32768) + (i.inner*1024)) + (j.outer*32)) + j.inner)\n",
      "          C[cse_var_1] = (A[cse_var_1] + B[cse_var_1])\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "---------cutting line---------\n",
      "@main = primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [1048576], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [1048576], []),\n",
      "             C: Buffer(C_2: Pointer(float32), float32, [1048576], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, C_1: C}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [1024, 1024], []), B_1: B_3: Buffer(B_2, float32, [1024, 1024], []), C_1: C_3: Buffer(C_2, float32, [1024, 1024], [])} {\n",
      "  for (i.outer: int32, 0, 32) {\n",
      "    for (j.outer: int32, 0, 32) {\n",
      "      for (j.inner: int32, 0, 32) {\n",
      "        for (i.inner: int32, 0, 32) {\n",
      "          let cse_var_1: int32 = ((((i.outer*32768) + (i.inner*1024)) + (j.outer*32)) + j.inner)\n",
      "          C[cse_var_1] = (A[cse_var_1] + B[cse_var_1])\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 1024\n",
    "A = te.placeholder((n, n), name='A')\n",
    "B = te.placeholder((n,n), name='B')\n",
    "C = te.compute((n, n), lambda i, j: A[i, j] + B[i, j], name='C')\n",
    "\n",
    "s = te.create_schedule(C.op)\n",
    "\n",
    "xo, xi = s[C].split(s[C].op.axis[0], factor=32)\n",
    "yo, yi = s[C].split(s[C].op.axis[1], factor=32)\n",
    "\n",
    "print(tvm.lower(s, [A, B, C], simple_mode=True))\n",
    "print(\"---------cutting line---------\")\n",
    "\n",
    "s[C].reorder(xo, yo, yi, xi)\n",
    "\n",
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tile\n",
    "\n",
    "# primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
    "#   attr = {\"global_symbol\": \"main\", \"tir.noalias\": True}\n",
    "#   buffers = {C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], []),\n",
    "#              B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], []),\n",
    "#              A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], [])}\n",
    "#   buffer_map = {A_1: A, B_1: B, C_1: C} {\n",
    "#   for (i: int32, 0, 1024) {\n",
    "#     for (j: int32, 0, 1024) {\n",
    "#       C_2[((i*1024) + j)] = 0f32\n",
    "#       for (K: int32, 0, 1024) {\n",
    "#         C_2[((i*1024) + j)] = ((float32*)C_2[((i*1024) + j)] + ((float32*)A_2[((i*1024) + K)]*(float32*)B_2[((K*1024) + j)]))\n",
    "#       }\n",
    "#     }\n",
    "#   }\n",
    "# }\n",
    "\n",
    "\n",
    "# ---------cutting line---------\n",
    "# primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
    "#   attr = {\"global_symbol\": \"main\", \"tir.noalias\": True}\n",
    "#   buffers = {C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], []),\n",
    "#              B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], []),\n",
    "#              A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], [])}\n",
    "#   buffer_map = {A_1: A, B_1: B, C_1: C} {\n",
    "#   for (i.outer: int32, 0, 32) {\n",
    "#     for (j.outer: int32, 0, 32) {\n",
    "#       for (i.inner: int32, 0, 32) {\n",
    "#         for (j.inner: int32, 0, 32) {\n",
    "#           C_2[((((i.outer*32768) + (i.inner*1024)) + (j.outer*32)) + j.inner)] = 0f32\n",
    "#           for (K: int32, 0, 1024) {\n",
    "#             C_2[((((i.outer*32768) + (i.inner*1024)) + (j.outer*32)) + j.inner)] = ((float32*)C_2[((((i.outer*32768) + (i.inner*1024)) + (j.outer*32)) + j.inner)] + ((float32*)A_2[(((i.outer*32768) + (i.inner*1024)) + K)]*(float32*)B_2[(((K*1024) + (j.outer*32)) + j.inner)]))\n",
    "#           }\n",
    "#         }\n",
    "#       }\n",
    "#     }\n",
    "#   }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@main = primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [1048576], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [1048576], []),\n",
      "             C: Buffer(C_2: Pointer(float32), float32, [1048576], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, C_1: C}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [1024, 1024], []), B_1: B_3: Buffer(B_2, float32, [1024, 1024], []), C_1: C_3: Buffer(C_2, float32, [1024, 1024], [])} {\n",
      "  for (x.outer: int32, 0, 32) {\n",
      "    for (y.outer: int32, 0, 32) {\n",
      "      for (x.inner: int32, 0, 32) {\n",
      "        for (y.inner: int32, 0, 32) {\n",
      "          let cse_var_1: int32 = ((((x.outer*32768) + (x.inner*1024)) + (y.outer*32)) + y.inner)\n",
      "          C[cse_var_1] = (A[cse_var_1] + B[cse_var_1])\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "---------cutting line---------\n",
      "@main = primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [1048576], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [1048576], []),\n",
      "             C: Buffer(C_2: Pointer(float32), float32, [1048576], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, C_1: C}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [1024, 1024], []), B_1: B_3: Buffer(B_2, float32, [1024, 1024], []), C_1: C_3: Buffer(C_2, float32, [1024, 1024], [])} {\n",
      "  for (x.outer: int32, 0, 32) {\n",
      "    for (y.outer: int32, 0, 32) {\n",
      "      for (x.inner: int32, 0, 32) {\n",
      "        let cse_var_1: int32 = (((x.outer*32768) + (x.inner*1024)) + (y.outer*32))\n",
      "        C[ramp(cse_var_1, 1, 32)] = (A[ramp(cse_var_1, 1, 32)] + B[ramp(cse_var_1, 1, 32)])\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "M = 1024\n",
    "N = 1024\n",
    "A = te.placeholder((M, N), name='A')\n",
    "B = te.placeholder((M, N), name='B')\n",
    "C = te.compute(\n",
    "           (M, N),\n",
    "           lambda x, y: A[x, y] + B[x, y],\n",
    "           name='C')\n",
    "\n",
    "s = te.create_schedule(C.op)\n",
    "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], 32, 32)\n",
    "\n",
    "print(tvm.lower(s, [A, B, C], simple_mode=True))\n",
    "print(\"---------cutting line---------\")\n",
    "\n",
    "s[C].vectorize(yi)\n",
    "\n",
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
